# -*- coding: utf-8 -*-
"""Inpainting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14DZITTk7W7d9tUlcuYh29VSeSnpcABEz
"""

import torch
from transformers import AutoImageProcessor, AutoModelForDepthEstimation
from transformers import Mask2FormerImageProcessor, Mask2FormerForUniversalSegmentation
from diffusers import ControlNetModel, StableDiffusionInpaintPipeline
from PIL import Image, ImageFilter, ImageDraw
import numpy as np
import cv2
import random
from typing import List, Tuple, Dict, Union
from scipy.signal import fftconvolve
import gradio as gr

# --- Global State for this specific app ---
_current_input_image_pil: Union[Image.Image, None] = None
_current_brush_radius: int = 80 # Default for ImageEditor's visual feedback
_current_negative_prompt: str = "lowres, watermark, banner, logo, watermark, contactinfo, text, deformed, blurry, blur, out of focus, out of frame, surreal, ugly"

# --- Determine Device ---
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
DTYPE = torch.float16 if DEVICE == "cuda" else torch.float32 # Use float16 for GPU, float32 for CPU
print(f"Using device: {DEVICE} with dtype: {DTYPE}")

inpaint_model = StableDiffusionInpaintPipeline.from_pretrained(
    "stabilityai/stable-diffusion-2-inpainting",
    torch_dtype=DTYPE,
).to(DEVICE)
print(f"Stable Diffusion Inpainting Pipeline loaded to {DEVICE}.")

"""# Main Logic"""

def load_and_preprocess_image(image: Union[Image.Image, np.ndarray]) -> Image.Image:
    """
    Loads an image (PIL or numpy array) and preprocesses it for model input (RGB conversion, resizing).
    """
    # Check if the image is a numpy array and convert it to PIL Image if necessary
    if isinstance(image, np.ndarray):
        # Ensure the numpy array is in a suitable format (e.g., uint8)
        if image.dtype != np.uint8:
             image = image.astype(np.uint8)
        image = Image.fromarray(image)
        print("Converted numpy array to PIL Image.")

    # Now process the PIL Image
    image = image.convert("RGB")
    print("image converted to RGB")
    image = image.resize((512, 512)) # Standardize size for models
    print("image resized to 512x512")
    return image

def convolution(mask: Image.Image, size=9) -> Image:
    """Method to blur the mask
    Args:
        mask (Image): masking image
        size (int, optional): size of the blur. Defaults to 9.
    Returns:
        Image: blurred mask
    """
    mask = np.array(mask.convert("L"))
    conv = np.ones((size, size)) / size**2
    mask_blended = fftconvolve(mask, conv, 'same')
    mask_blended = mask_blended.astype(np.uint8).copy()

    border = size

    # replace borders with original values
    mask_blended[:border, :] = mask[:border, :]
    mask_blended[-border:, :] = mask[-border:, :]
    mask_blended[:, :border] = mask[:, :border]
    mask_blended[:, -border:] = mask[:, -border:]

    return Image.fromarray(mask_blended).convert("L")

def postprocess_image_masking(inpainted: Image, image: Image, mask: Image) -> Image:
    """Method to postprocess the inpainted image
    Args:
        inpainted (Image): inpainted image
        image (Image): original image
        mask (Image): mask
    Returns:
        Image: inpainted image
    """
    final_inpainted = Image.composite(inpainted.convert("RGBA"), image.convert("RGBA"), mask)
    return final_inpainted.convert("RGB")

def make_inpainting(
    positive_prompt: str,
    image: Image.Image,
    mask_image: Image.Image,
    # negative_prompt: str,
    seed: int = 42
) -> Image.Image:
    """
    Performs inpainting using the Stable Diffusion Inpainting pipeline.
    """
    global _current_negative_prompt
    pipe = inpaint_model
    generator = torch.Generator(device=DEVICE).manual_seed(seed)

    image = image.resize((512, 512))
    mask_image = Image.fromarray((mask_image * 255).astype(np.uint8))
    mask_image = mask_image.resize((512, 512)).convert("L")
    mask_image_postproc = convolution(mask_image)

    generated_image = pipe(
        prompt=positive_prompt,
        negative_prompt = _current_negative_prompt,
        image=image,
        mask_image=mask_image,
        num_inference_steps=50,
        generator=generator
    ).images[0]
    generated_image = postprocess_image_masking(generated_image, image, mask_image_postproc)
    return generated_image

def get_mask(image_mask: np.ndarray) -> np.ndarray:
    """Get the mask from the segmentation mask.
    Args:
        image_mask (np.ndarray): segmentation mask
    Returns:
        np.ndarray: mask
    """
    # average the colors of the segmentation masks
    average_color = np.mean(image_mask, axis=(2))
    mask = average_color[:, :] > 0
    if mask.sum() > 0:
        mask = mask * 1
    return mask
def on_upload_image(input_image_editor_data: Dict[str, Union[Image.Image, None]]) -> Tuple[Dict[str, Union[Image.Image, None]], gr.Textbox,  gr.Button]:
    """
    Handles the initial image upload and processing for Inpainting mode.
    Returns a dictionary for gr.ImageEditor.
    """
    global _current_input_image_pil


    # Extract the uploaded image from the ImageEditor's dictionary output
    # Corrected key to extract the background image
    uploaded_image_pil = input_image_editor_data.get('background')


    if uploaded_image_pil is None:
        print("Image is none - This should not happen on successful upload") # Added for debugging
        return (
            {"background": None, "layers": [], "composite": None}, # Corrected dictionary for ImageEditor
            gr.update(value="", interactive=False),
            # gr.update(value="", interactive=False),
            # gr.update(interactive=False),
            gr.update(interactive=False)
        )

    try:

        _current_input_image_pil = load_and_preprocess_image(uploaded_image_pil)
        print("Processed image successfully.") # Added for debugging

        input_image_editor_data['background'] = _current_input_image_pil
        # input_image_editor_data['layers'] = []
        # input_image_editor_data['composite'] = _current_input_image_pil

        print("Returning updated components...") # Added for debugging

        return (
            gr.update(value = input_image_editor_data), # Corrected dictionary for ImageEditor
            gr.update(value="", interactive=True),
            # gr.update(value=_current_negative_prompt, interactive=True),
            # gr.update(interactive=True), # Enable seed slider
            gr.update(interactive=True)  # Enable generate button
        )
        # print("current image is returned") # This print statement is now reachable but not needed after return

    except Exception as e:
        print(f"Error during image processing: {e}")
        gr.Warning(f"Failed to process image: {e}")
        return (
            {"background": None, "layers": [], "composite": None}, # Corrected dictionary for ImageEditor
            gr.update(value="", interactive=False),
            # gr.update(value="", interactive=False),
            # gr.update(interactive=False),
            gr.update(interactive=False)
        )

def handle_generate_button(
    positive_prompt: str,
    # # negative_prompt: str,
    # current_seed: int,
    input_image_editor_data: Dict[str, Union[Image.Image, None]],
) -> Tuple[gr.Image]:
    """
    Handles the main 'Generate Output' button click for Inpainting mode.

    """
    current_image = input_image_editor_data.get('background')
    current_mask_layer = input_image_editor_data.get('layers')
    current_mask = current_mask_layer[1] if current_mask_layer and len(current_mask_layer) > 0 else None

    if current_image is None:
        gr.Warning("Please upload an image first.")
        return None, gr.update(interactive=False)
    if current_mask is None:
        gr.Warning("Please draw a mask on the image for Inpainting.")
        return None, gr.update(interactive=False)
    if not positive_prompt:
        gr.Warning("Positive prompt is required for 'Inpainting' mode.")
        return None, gr.update(interactive=False)

    # Ensure current_image is a PIL Image before resizing
    if isinstance(current_image, np.ndarray):
        current_image = Image.fromarray(current_image.astype(np.uint8))
        if current_image.mode == 'RGBA': # Remove alpha channel if present
            current_image = current_image.convert('RGB')


       # Check if current_mask is a numpy array and convert to PIL Image if necessary
    if not isinstance(current_mask, np.ndarray):
        current_mask = np.array(current_mask)

    mask = get_mask(current_mask)


    try:
        output_img = make_inpainting(
            positive_prompt=positive_prompt,
            image=current_image,
            mask_image=current_mask,
            # negative_prompt=negative_prompt,
            seed=random.randint(0, 1000000)
        )

        if isinstance(output_img, np.ndarray):
              output_image = Image.fromarray(output_img)
    except Exception as e:
        # Catching the specific ClientDisconnect error from starlette
        if "ClientDisconnect" in str(e):
             gr.Warning("Client disconnected during processing. Please keep the browser tab open.")
             print("Client disconnected during processing.")
        else:
            print(f"Error during Inpainting: {e}")
            gr.Warning(f"Error during Inpainting: {e}")
        return None, gr.update(interactive=False)

    return output_img